{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUDjuQsOo3-D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "groq_api_key = userdata.get('groq_api_key')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v5VoC7Iq6qf",
        "outputId": "373d7bfa-ba91-452b-f1a8-e9156e665037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Collecting gradio\n",
            "  Using cached gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Using cached gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "S5L9kx0qpLJO",
        "outputId": "5ff1ad98-4204-4775-ebba-7a185e19b0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-185ebe932d89>:224: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://06a8c332d60a2b72f2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://06a8c332d60a2b72f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any\n",
        "import gradio as gr\n",
        "\n",
        "# Install required packages if not already installed\n",
        "# Uncomment these lines if you need to install packages\n",
        "# import subprocess\n",
        "# subprocess.run([\"pip\", \"install\", \"-q\", \"groq\", \"gradio\"])\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "class CollegeCounselorChatbot:\n",
        "    def __init__(self, api_key, name=\"Lauren\"):\n",
        "        self.name = name\n",
        "        self.model = \"llama-3.1-8b-instant\"\n",
        "\n",
        "        # Initialize Groq client with the provided API key\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "        self.conversation_history = [\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"\n",
        "            You are {name}, an AI college counselor for Indian students. Your goal is to collect information about the student and provide personalized college recommendations.\n",
        "\n",
        "            You need to gather these key details from the student through natural conversation:\n",
        "            1. Marks_10th - Student's 10th standard marks percentage\n",
        "            2. Marks_12th - Student's 12th standard marks percentage\n",
        "            3. JEE_Score - JEE score if applicable\n",
        "            4. Budget - How much they can afford for their entire education\n",
        "            5. Preferred_Location - Which part of India they prefer to study in\n",
        "            6. Gender - Student's gender\n",
        "            7. Target_Exam - Which entrance exams they're targeting\n",
        "            8. State_Board - Which educational board they studied under\n",
        "            9. Category - Their reservation category (General, OBC, SC, ST, etc.)\n",
        "            10. Extra_Curriculars - Any extracurricular activities/achievements\n",
        "            11. Future_Goal - Career aspirations or goals\n",
        "\n",
        "            Be friendly, conversational, and encouraging. First introduce yourself briefly and start collecting information.\n",
        "            Only move on to college recommendations after collecting all the necessary information.\n",
        "\n",
        "            When making recommendations, suggest 3-5 colleges that match their profile, explaining why each college is suitable,\n",
        "            key programs offered, admission requirements, and costs. Also provide practical next steps for application.\n",
        "            \"\"\"}\n",
        "        ]\n",
        "        self.student_data = {\n",
        "            'Marks_10th': None,\n",
        "            'Marks_12th': None,\n",
        "            'JEE_Score': None,\n",
        "            'Budget': None,\n",
        "            'Preferred_Location': None,\n",
        "            'Gender': None,\n",
        "            'Target_Exam': None,\n",
        "            'State_Board': None,\n",
        "            'Category': None,\n",
        "            'Extra_Curriculars': None,\n",
        "            'Future_Goal': None\n",
        "        }\n",
        "        self.data_collected = False\n",
        "\n",
        "        # Sample college database\n",
        "        self.colleges = [\n",
        "            {\"name\": \"IIT Bombay\", \"min_jee\": 8000, \"fees\": 800000, \"location\": \"Mumbai\", \"acceptance_rate\": \"Very Low\", \"specialties\": [\"Engineering\", \"Technology\"]},\n",
        "            {\"name\": \"IIT Delhi\", \"min_jee\": 9000, \"fees\": 750000, \"location\": \"Delhi\", \"acceptance_rate\": \"Very Low\", \"specialties\": [\"Engineering\", \"Computer Science\"]},\n",
        "            {\"name\": \"BITS Pilani\", \"min_jee\": 15000, \"fees\": 1200000, \"location\": \"Rajasthan\", \"acceptance_rate\": \"Low\", \"specialties\": [\"Engineering\", \"Pharmacy\"]},\n",
        "            {\"name\": \"VIT Vellore\", \"min_jee\": 50000, \"fees\": 900000, \"location\": \"Tamil Nadu\", \"acceptance_rate\": \"Moderate\", \"specialties\": [\"Engineering\", \"Bio-Technology\"]},\n",
        "            {\"name\": \"Manipal Institute of Technology\", \"min_jee\": 70000, \"fees\": 1500000, \"location\": \"Karnataka\", \"acceptance_rate\": \"Moderate\", \"specialties\": [\"Engineering\", \"Medicine\"]},\n",
        "            {\"name\": \"NIT Trichy\", \"min_jee\": 20000, \"fees\": 500000, \"location\": \"Tamil Nadu\", \"acceptance_rate\": \"Low\", \"specialties\": [\"Engineering\"]},\n",
        "            {\"name\": \"Delhi University\", \"min_jee\": None, \"fees\": 200000, \"location\": \"Delhi\", \"acceptance_rate\": \"Moderate\", \"specialties\": [\"Arts\", \"Commerce\", \"Science\"]},\n",
        "            {\"name\": \"AIIMS Delhi\", \"min_jee\": None, \"fees\": 600000, \"location\": \"Delhi\", \"acceptance_rate\": \"Very Low\", \"specialties\": [\"Medicine\"]},\n",
        "            {\"name\": \"St. Stephen's College\", \"min_jee\": None, \"fees\": 300000, \"location\": \"Delhi\", \"acceptance_rate\": \"Low\", \"specialties\": [\"Arts\", \"Science\"]},\n",
        "            {\"name\": \"Christ University\", \"min_jee\": None, \"fees\": 500000, \"location\": \"Bangalore\", \"acceptance_rate\": \"Moderate\", \"specialties\": [\"Commerce\", \"Management\"]},\n",
        "        ]\n",
        "\n",
        "    def extract_information(self, message):\n",
        "        \"\"\"Extract student information from user messages with improved patterns\"\"\"\n",
        "        # Define patterns to recognize information (improved for better recognition)\n",
        "        patterns = {\n",
        "            'Marks_10th': r'(?:10th|10 th|tenth|x)(?:\\s+(?:standard|grade|class|marks|score|percentage))?\\s*(?::|is|are|=|-)?\\s*(\\d{1,3}(?:\\.\\d{1,2})?)',\n",
        "            'Marks_12th': r'(?:12th|12 th|twelfth|xii)(?:\\s+(?:standard|grade|class|marks|score|percentage))?\\s*(?::|is|are|=|-)?\\s*(\\d{1,3}(?:\\.\\d{1,2})?)',\n",
        "            'JEE_Score': r'(?:jee|joint entrance)(?:\\s+(?:score|marks|rank|result))?\\s*(?::|is|are|=|-)?\\s*(\\d+)',\n",
        "            'Budget': r'(?:budget|afford|cost|fees|spending)(?:\\s+(?:is|of|around|approximately|approx|about))?\\s*(?::|=|-)?\\s*(?:rs\\.?|inr)?(?:\\s*)(\\d+(?:\\.\\d+)?(?:\\s*(?:lakh|lakhs|lac|lacs|l|k|cr|crore|crores))?)',\n",
        "            'Preferred_Location': r'(?:prefer|want|like)(?:red)?(?:\\s+to\\s+study)?\\s+(?:in|at|near)\\s+([a-zA-Z ]+)',\n",
        "            'Gender': r'(?:gender|sex|i am a)\\s*(?:is|:|=|-)?\\s*\\b(male|female|other|boy|girl|man|woman)\\b',\n",
        "            'Target_Exam': r'(?:preparing for|taking|giving|target(?:ing)?|writing)(?:\\s+the)?\\s+(jee|neet|clat|cat|gate)',\n",
        "            'State_Board': r'(?:studied|completed|finished|did)(?:\\s+(?:from|under|in))?\\s+(cbse|icse|state board|international)',\n",
        "            'Category': r'(?:category|reservation|quota)\\s*(?:is|:|=|-)?\\s*\\b(general|obc|sc|st)\\b',\n",
        "        }\n",
        "\n",
        "        # Check for matches in the user message\n",
        "        for key, pattern in patterns.items():\n",
        "            match = re.search(pattern, message.lower())\n",
        "            if match and not self.student_data[key]:\n",
        "                self.student_data[key] = match.group(1)\n",
        "\n",
        "        # Special handling for longer text fields\n",
        "        # Extract Extra-Curriculars\n",
        "        if not self.student_data['Extra_Curriculars'] and ('extracurricular' in message.lower() or 'extra curricular' in message.lower() or 'activities' in message.lower()):\n",
        "            parts = re.split(r'(?:my extracurriculars are|my extra curriculars are|my activities include|i participate in|i am involved in|i do)', message.lower(), flags=re.IGNORECASE)\n",
        "            if len(parts) > 1:\n",
        "                self.student_data['Extra_Curriculars'] = parts[1].strip()\n",
        "\n",
        "        # Extract Future Goals\n",
        "        if not self.student_data['Future_Goal'] and ('goal' in message.lower() or 'aspiration' in message.lower() or 'future' in message.lower() or 'career' in message.lower()):\n",
        "            parts = re.split(r'(?:my goal is|my aspiration is|in the future|my career goal|i want to become|i want to be)', message.lower(), flags=re.IGNORECASE)\n",
        "            if len(parts) > 1:\n",
        "                self.student_data['Future_Goal'] = parts[1].strip()\n",
        "\n",
        "    def check_data_completion(self):\n",
        "        \"\"\"Check if all required data has been collected\"\"\"\n",
        "        missing_fields = [k for k, v in self.student_data.items() if v is None]\n",
        "        return len(missing_fields) == 0\n",
        "\n",
        "    def get_missing_fields(self):\n",
        "        \"\"\"Get list of missing fields\"\"\"\n",
        "        return [k for k, v in self.student_data.items() if v is None]\n",
        "\n",
        "    def format_colleges_for_prompt(self):\n",
        "        \"\"\"Format college data for inclusion in the prompt\"\"\"\n",
        "        colleges_text = \"College Database:\\n\"\n",
        "        for college in self.colleges:\n",
        "            colleges_text += f\"- {college['name']}: Location: {college['location']}, \"\n",
        "            colleges_text += f\"Min JEE Rank (if applicable): {college['min_jee']}, \"\n",
        "            colleges_text += f\"Approximate Fees: {college['fees']}, \"\n",
        "            colleges_text += f\"Acceptance Rate: {college['acceptance_rate']}, \"\n",
        "            colleges_text += f\"Specialties: {', '.join(college['specialties'])}\\n\"\n",
        "        return colleges_text\n",
        "\n",
        "    def chat(self, message, history):\n",
        "        \"\"\"Process user message and generate response\"\"\"\n",
        "        # Extract information from the user message\n",
        "        self.extract_information(message)\n",
        "\n",
        "        # Prepare user message for LLM\n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        # Check if we have all the required information\n",
        "        if not self.data_collected:\n",
        "            self.data_collected = self.check_data_completion()\n",
        "\n",
        "        # Prepare custom instructions for LLM based on conversation state\n",
        "        if self.data_collected and not any(msg['content'].startswith('PROVIDE RECOMMENDATIONS') for msg in self.conversation_history if msg['role'] == 'system'):\n",
        "            # All data collected, time for recommendations\n",
        "            student_profile = \"\\n\".join([f\"{k}: {v}\" for k, v in self.student_data.items()])\n",
        "            colleges_data = self.format_colleges_for_prompt()\n",
        "\n",
        "            self.conversation_history.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"\"\"\n",
        "                PROVIDE RECOMMENDATIONS NOW. All required information has been collected.\n",
        "\n",
        "                Student Profile:\n",
        "                {student_profile}\n",
        "\n",
        "                {colleges_data}\n",
        "\n",
        "                Based on this student's profile, recommend 3-5 suitable colleges or universities from the database that match their profile.\n",
        "                For each recommendation, explain:\n",
        "                1. Why this college is a good fit\n",
        "                2. Key programs relevant to their interests\n",
        "                3. Admission requirements and competitiveness\n",
        "                4. Estimated costs and financial considerations\n",
        "\n",
        "                Also provide 2-3 practical next steps the student should take to prepare their applications.\n",
        "                Format your response in a friendly, encouraging manner while being honest about admission chances.\n",
        "                \"\"\"\n",
        "            })\n",
        "        elif not self.data_collected:\n",
        "            # Still collecting data\n",
        "            missing_fields = self.get_missing_fields()\n",
        "            next_field = missing_fields[0] if missing_fields else None\n",
        "\n",
        "            if next_field:\n",
        "                self.conversation_history.append({\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": f\"\"\"\n",
        "                    You still need to collect more information from the student.\n",
        "\n",
        "                    Information collected so far:\n",
        "                    {json.dumps({k: v for k, v in self.student_data.items() if v is not None}, indent=2)}\n",
        "\n",
        "                    Focus on getting information for: {next_field}\n",
        "\n",
        "                    Ask in a conversational, friendly way. Don't list all missing fields at once.\n",
        "                    Remember to stay conversational and acknowledge what the student says.\n",
        "                    \"\"\"\n",
        "                })\n",
        "\n",
        "        try:\n",
        "            # Generate response using Groq API\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=self.conversation_history,\n",
        "                temperature=0.7,\n",
        "                max_tokens=1000,\n",
        "            )\n",
        "\n",
        "            assistant_response = response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            assistant_response = f\"I'm sorry, there was an error generating a response: {str(e)}\"\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "        # Add assistant response to history\n",
        "        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "        return assistant_response\n",
        "\n",
        "\n",
        "def create_chatbot_interface(api_key):\n",
        "    \"\"\"Create the Gradio interface for the chatbot\"\"\"\n",
        "    counselor = CollegeCounselorChatbot(api_key=api_key, name=\"Lauren\")\n",
        "\n",
        "    with gr.Blocks(title=\"Lauren - AI College Counselor\") as app:\n",
        "        gr.Markdown(\"# 🎓 Lauren - Your AI College Counselor\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Welcome to your personal college counseling session with Lauren!\n",
        "\n",
        "        Share information about your academic background, preferences, and goals through natural conversation.\n",
        "        Lauren will guide you through the process and provide personalized college recommendations for your profile.\n",
        "\n",
        "        Let's get started!\n",
        "        \"\"\")\n",
        "\n",
        "        chatbot = gr.Chatbot(\n",
        "            height=500,\n",
        "            show_copy_button=True,\n",
        "            # Use a simple fallback for avatar image in case the URL isn't accessible\n",
        "            avatar_images=(None, \"https://i.imgur.com/mY2MHR3.png\")\n",
        "        )\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Hi Lauren! I need help finding the right college...\",\n",
        "            container=False,\n",
        "            scale=7\n",
        "        )\n",
        "        with gr.Row():\n",
        "            submit = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "            clear = gr.Button(\"Clear Conversation\", scale=1)\n",
        "\n",
        "        # Set up the greeting message\n",
        "        initial_greeting = \"\"\"\n",
        "        👋 Hi there! I'm Lauren, your personal AI college counselor.\n",
        "\n",
        "        I'm here to help you find the best colleges based on your academic profile, preferences, and future goals.\n",
        "        Let's have a conversation about your background and what you're looking for!\n",
        "\n",
        "        Could you start by telling me about your 10th and 12th standard marks?\n",
        "        \"\"\"\n",
        "\n",
        "        # Set up interactions\n",
        "        def respond(message, chat_history):\n",
        "            if not message:\n",
        "                return chat_history\n",
        "\n",
        "            response = counselor.chat(message, chat_history)\n",
        "            chat_history.append((message, response))\n",
        "            return \"\", chat_history\n",
        "\n",
        "        # Set up clear function\n",
        "        def clear_conversation():\n",
        "            # Reset the counselor with the same API key\n",
        "            nonlocal counselor\n",
        "            counselor = CollegeCounselorChatbot(api_key=api_key, name=\"Lauren\")\n",
        "            return []\n",
        "\n",
        "        # Set up event handlers\n",
        "        msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "        submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
        "        clear.click(clear_conversation, None, chatbot)\n",
        "\n",
        "        # Set initial message on page load\n",
        "        chatbot.value = [(\"\", initial_greeting)]\n",
        "\n",
        "    return app\n",
        "\n",
        "\n",
        "# Main application function\n",
        "def main():\n",
        "    # Get API key - provide options for different environments\n",
        "    api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "    # If running in Google Colab, try to get from userdata\n",
        "    if not api_key:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            api_key = userdata.get('groq_api_key')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # If still no API key, prompt the user\n",
        "    if not api_key:\n",
        "        print(\"No Groq API key found in environment variables.\")\n",
        "        api_key_input = gr.Textbox(\n",
        "            label=\"Enter your Groq API Key\",\n",
        "            placeholder=\"Enter your Groq API key here\",\n",
        "            type=\"password\"\n",
        "        )\n",
        "\n",
        "        def launch_app(key):\n",
        "            if not key:\n",
        "                return \"Please enter a valid API key\"\n",
        "\n",
        "            app = create_chatbot_interface(key)\n",
        "            app.launch(share=True)\n",
        "            return \"Chatbot launched!\"\n",
        "\n",
        "        with gr.Blocks() as setup_app:\n",
        "            gr.Markdown(\"# Lauren College Counselor Setup\")\n",
        "            gr.Markdown(\"Please enter your Groq API key to start the chatbot\")\n",
        "            api_key_input.render()\n",
        "            launch_button = gr.Button(\"Launch Chatbot\")\n",
        "            output = gr.Textbox(label=\"Status\")\n",
        "            launch_button.click(launch_app, inputs=api_key_input, outputs=output)\n",
        "\n",
        "        setup_app.launch(share=True)\n",
        "    else:\n",
        "        # API key is available, launch the chatbot directly\n",
        "        app = create_chatbot_interface(api_key)\n",
        "        app.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66kehiNIpLGv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieqHXatBpLCK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}